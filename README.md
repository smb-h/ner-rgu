# NER-RGU

NER RGU PhD Interview Task 2025

## Note
I **haven't used** any AI tool for this task.

## Ideas
- Simple tokenization and analyse the patterns that people mostly use while introducing themselves. (current method)
- A liltle more advance than previous idea to use positional encoding instead of checking manually.
- Train a name entity linking model to find the dependencies of each token, so we can find the relations betweem names and speaker tags.
- Use an small LLM to extract entities and feed it to another model for validation check whether the entities are correct or not.

## Results & Limits
I had 1 original sample of data to work on and I've added 4 more samples generated by ChatGPT o1 which were my test cases. 

I did get **Accuracy 1.0** for all test cases. 

Even though on edge cases this method could fail like if the introduction pattern would be something odd or in a different manner which we don't have in our patterns we would fail, but for a 3 hours task and 4 test cases with a straight method we got accuracy 1 which is pretty impressive i think.

### Implementation Details
- I have used Regex to extract SpeakerX pattern from the text.
- Then with help of SpaCy NER pipeline and corpus 'en_core_web_lg' extracted entities and their appointed class. Which we only wanted *PERSON* class.
- Then I did iterate through sentences to find introduction patterns and used extracted entities to match the names they were mentioning
- And at the end replaced the SpeakerX with their related names.

```
PRE_PATTERNS_FOR_INTRO = [
    "my name is",
    "i am",
    "i’m",
    "i'm",
    "they call me",
    "i’m called",
    "i'm called",
    "i am called",
]
POST_PATTERNS_FOR_INTRO = [
    "that is me",
    "that’s me",
    "that's me",
    "that is me",
    "that would be me",
]
```
Note that with preprocessing we can reduce these patterns which I skipped for now.

#### Synthesis Data
To evaluate my method I have used ChatGPT o1 to create 4 more data samples. Here is the prompt:

    
```
I have given you a sample transcript of a brief conversation between 2 attendees at a meeting. The conversation consists of each attendee introducing themselves in different ways, while also referring to other people. The following is an example:
Speaker1: Hi, my name is John Smith.
Speaker2: Hi John, hi everyone, my name is Jane Brown.
Speaker1: Nice to meet you, Jane.
...
Help me write another scenario with multiple speakers while each attendee introducing themselves in different ways they can also refer to other people. keep the format exactly like provided example and gimme speaker and name pair in JSON format like the following:
Output:
```json
{
    "text" : Speaker1: Hi, my name is John Smith.
Speaker2: Hi John, hi everyone, my name is Jane Brown.
Speaker1: Nice to meet you, Jane."
    "labels": {
        "Speaker1": "John Smith",
        "Speaker2": "Jane Brown"
    }
}
```

## How to run
Create a virtual environment on your system and install requrements.txt
```
pip install -r requirements.txt
```

In the main project directory run
```
python -m ner_rgu.modeling.predict org
```
org is the name of original sample, you can also use the names in `data/raw` which are test_1, test_2, test_3, test_4.

The output would be like this
```
Ground truth:
{'Speaker1': 'Alice Roberts', 'Speaker2': 'David Smith', 'Speaker3': 'Sally Jones', 'Speaker4': 'Paul Owens'}

Predicted:
{'Speaker1': 'Alice Roberts', 'Speaker2': 'David Smith', 'Speaker3': 'Sally Jones', 'Speaker4': 'Paul Owens'}

Final result:
Alice Roberts: Hello, I’d like to introduce myself. My name is Alice Roberts, and I’m the head of regional sales.  I’ll be chairing this meeting today. The first thing I’d like to do is go round the room and have everyone introduce themselves.

David Smith: Hi, I’m David Smith and I work in book sales alongside Sally here.

Sally Jones: Thanks David. So as David said, I’m Sally, Sally Jones, I’ve been in book sales for 10 years now.

Paul Owens: Nice to meet everyone, although I already know Alice. Anyway, Paul Owens, that’s me. I’m interested in buying some of your stuff, especially those new Richard Osman books. Hopefully we can do business together.

Alice Roberts: Thanks everyone, and yes just to bring David and Sally up to speed Paul and I had an initial meeting last week.

Sally Jones: Ah, that explains why we’re here!

David Smith: Yes.

============
Achieved accuracy: 1.0
```

## Project Structure

```
├── data
│   ├── processed      <- Labels in json format.
│   └── raw            <- The original, immutable data files.
│
│
├── notebooks          <- Jupyter notebooks. The playground notebook is in this directory.
│
│
├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
│                         generated with `pip freeze > requirements.txt`
│
└── ner_rgu   <- Source code for use in this project.
    │
    ├── config.py               <- Store useful variables and configuration
    │
    ├── dataset.py              <- Scripts to read data
    │
    │
    ├── modeling                
    │   ├── __init__.py 
    │   ├── predict.py          <- Main code to run model pipeline.            
```
